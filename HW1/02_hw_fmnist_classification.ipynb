{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "# Домашнее задание №1\n",
        "## Часть2: Классификация FashionMNIST\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/rads_ai\n",
        "\n",
        "В данном задании вам предстоит решить достаточно простую задачу классификации изображений с помощью сверточных нейронных сетей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YRSn_7V7ldUi"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YLlSD-wldUi"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTlkf_nlldUi",
        "outputId": "81df732c-0ffe-4c64-bab8-a252ec8be952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-10 18:25:13--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-09-10 18:25:14--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-10 18:25:14 (226 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_HCsi46uldUj"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3WygtlSyldUj"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "34a18b5d-f919-4f0f-927e-8533665c6039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 8')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FashionMNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Сверточные слои - cвёртка ищет локальные паттерны (линии, углы, текстуры)\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # (1, 28, 28) -> (32, 28, 28)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # (32, 14, 14) -> (64, 14, 14)\n",
        "\n",
        "        # Сжатие картинки в 4 раза\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Во время тренировки обнуляет случайные нейроны (25%) в полносвязной части\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        # Полносвязные слои\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Creating model instance\n",
        "model_task_1 = FashionMNISTNet()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35f6505-18c0-4b62-dac3-403d188df634"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTNet(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "08d60b6e-54a0-4f17-8556-a21f0f9fa462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263919d0-7258-49d7-e698-74e3b7ad7f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | loss: 0.1340\n",
            "Epoch [2/10] | loss: 0.1192\n",
            "Epoch [3/10] | loss: 0.1115\n",
            "Epoch [4/10] | loss: 0.1024\n",
            "Epoch [5/10] | loss: 0.0944\n",
            "Epoch [6/10] | loss: 0.0898\n",
            "Epoch [7/10] | loss: 0.0834\n",
            "Epoch [8/10] | loss: 0.0760\n",
            "Epoch [9/10] | loss: 0.0751\n",
            "Epoch [10/10] | loss: 0.0732\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model_task_1.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_1.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for x, y in train_data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        logits = model_task_1(x)\n",
        "        loss = loss_func(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | loss: {epoch_loss/len(train_data_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fef5f8-185d-408f-b1d1-ae685ac8a5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.98628\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b209fe1b-3d26-430e-bbfb-87c0ea7c56da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9211\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E55FcvE_ldUk"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHu66Y5MldUk",
        "outputId": "0b0f2021-ee49-4291-adf3-4a02dbab5f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtMk6r1BldUk"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}